{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleus challenge using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRAIN_INSTANCES = None  # for entire set: None\n",
    "REDO_TRAINING = False\n",
    "STEPS_PER_EPOCH = 10\n",
    "N_EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'data/data-science-bowl-2018/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join(dataDir, 'stage1_train_labels.csv/stage1_train_labels.csv'))\n",
    "train_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training paths and meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob.glob(os.path.join(dataDir, 'stage1_*', '*', '*', '*.png'))\n",
    "img_df = pd.DataFrame({'path': all_images})\n",
    "\n",
    "print('An exemplary data path with indices of split:')\n",
    "print(*map(lambda x: (x[0]-6, x[1]), enumerate(img_df['path'].iloc[0].split('/'))), sep='\\n', end='\\n\\n')\n",
    "\n",
    "img_id = lambda x: x.split('/')[-3]\n",
    "img_type = lambda in_path: in_path.split('/')[-2]\n",
    "img_group = lambda in_path: in_path.split('/')[-4].split('_')[1]\n",
    "img_stage = lambda in_path: in_path.split('/')[-4].split('_')[0]\n",
    "                           \n",
    "img_df['ImageId'] = img_df['path'].map(img_id)\n",
    "img_df['ImageType'] = img_df['path'].map(img_type)\n",
    "img_df['TrainingSplit'] = img_df['path'].map(img_group)\n",
    "img_df['Stage'] = img_df['path'].map(img_stage)\n",
    "\n",
    "print(img_df.info())\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with training data (image and mask paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "train_df = img_df.query('TrainingSplit==\"train\"')\n",
    "train_rows = []\n",
    "group_cols = ['Stage', 'ImageId']\n",
    "\n",
    "count = 0\n",
    "for group, rows in train_df.groupby(group_cols):\n",
    "    count += 1\n",
    "    if MAX_TRAIN_INSTANCES is not None and count > MAX_TRAIN_INSTANCES:\n",
    "        break\n",
    "    #     print('group', group, 'contains', len(rows), 'rows')\n",
    "    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, group)}\n",
    "    c_row['images'] = rows.query('ImageType == \"images\"')['path'].values.tolist()\n",
    "    c_row['masks'] = rows.query('ImageType == \"masks\"')['path'].values.tolist()\n",
    "    train_rows += [c_row]\n",
    "    \n",
    "train_img_df = pd.DataFrame(train_rows)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def read(in_img_list):\n",
    "    assert (len(in_img_list) == 1), 'more than one image for this training instance. Shape: ' + str(in_img_list.shape)\n",
    "    return imread(in_img_list[0])\n",
    "\n",
    "IMG_CHANNELS = 3  # restrict pixels to RGB\n",
    "train_img_df['images'] = train_img_df['images'].map(read).map(lambda x: x[:,:,:IMG_CHANNELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze intensity distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df['Red'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]))\n",
    "train_img_df['Green'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,1]))\n",
    "train_img_df['Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,2]))\n",
    "train_img_df['Gray'] = train_img_df['images'].map(lambda x: np.mean(x))\n",
    "train_img_df['Red-Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]-x[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_img_df[['Gray', 'Red', 'Green', 'Blue', 'Red-Blue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df['images'].map(lambda x: x.shape).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using a single combined mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the masks and save them in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def read_and_stack(in_img_list):\n",
    "    return np.sum(np.stack([imread(c_img) for c_img in in_img_list], 0), 0) / 255.0\n",
    "\n",
    "train_img_df['masks'] = train_img_df['masks'].map(read_and_stack).map(lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show some of the pictures with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 6\n",
    "fig, m_axs = plt.subplots(2, n_img, figsize = (12, 4))\n",
    "for (c_row_idx, c_row), (c_im, c_lab) in zip(train_img_df.sample(n_img).iterrows(), \n",
    "                                     m_axs.T):\n",
    "    c_im.imshow(c_row['images'])\n",
    "    c_im.axis('off')\n",
    "    c_im.set_title('Microscope ' + str(c_row_idx))\n",
    "    \n",
    "    c_lab.imshow(c_row['masks'])\n",
    "    c_lab.axis('off')\n",
    "    c_lab.set_title('Labeled ' + str(c_row_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, UpSampling2D, Lambda\n",
    "simple_cnn = Sequential()\n",
    "simple_cnn.add(BatchNormalization(input_shape = (None, None, IMG_CHANNELS), \n",
    "                                  name = 'NormalizeInput'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n",
    "# use dilations to get a slightly larger field of view\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n",
    "simple_cnn.add(Conv2D(32, kernel_size = (3,3), dilation_rate = 3, padding = 'same'))\n",
    "\n",
    "# the final processing\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (1,1), padding = 'same'))\n",
    "simple_cnn.add(Conv2D(1, kernel_size = (1,1), padding = 'same', activation = 'sigmoid'))\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom loss to match competition objective\n",
    "\n",
    "Use Dice score, see [here](https://arxiv.org/pdf/1707.00478.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "smooth = 1.\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "simple_cnn.compile(optimizer = 'adam', loss = dice_coef_loss, metrics = [dice_coef, 'acc', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one image at a time for training (training step = one image, one epoch finished when all images processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gen():\n",
    "    while True:\n",
    "        for _, c_row in train_img_df.iterrows():\n",
    "            yield np.expand_dims(c_row['images'],0), np.expand_dims(np.expand_dims(c_row['masks'],-1),0)\n",
    "\n",
    "nxt = next(simple_gen())\n",
    "print('Elements in each generated object:', len(nxt))\n",
    "print('Shape of instance data: ', nxt[0].shape)\n",
    "print('Shape of instance label:', nxt[1].shape)\n",
    "# print(nxt[1][0][255][255][0])\n",
    "# print(nxt[0][0][255][255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "if REDO_TRAINING:\n",
    "\n",
    "#     simple_cnn.fit_generator(simple_gen(), steps_per_epoch=train_img_df.shape[0], epochs = N_EPOCHS)\n",
    "    simple_cnn.fit_generator(simple_gen(), STEPS_PER_EPOCH, epochs = N_EPOCHS)\n",
    "    simple_cnn.save('simple_gen.h5')    \n",
    "    \n",
    "else:\n",
    "    simple_cnn = load_model('simple_gen.h5', custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using separate masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
