{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nucleus challenge using a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TRAIN_INSTANCES = None  # for entire set: None\n",
    "REDO_TRAINING = True\n",
    "BATCH_SIZE = 2\n",
    "STEPS_PER_EPOCH = 100\n",
    "N_EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'data/data-science-bowl-2018/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(os.path.join(dataDir, 'stage1_train_labels.csv/stage1_train_labels.csv'))\n",
    "train_labels['EncodedPixels'] = train_labels['EncodedPixels'].map(lambda ep: [int(x) for x in ep.split(' ')])\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training paths and meta info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = glob.glob(os.path.join(dataDir, 'stage1_*', '*', '*', '*.png'))\n",
    "img_df = pd.DataFrame({'path': all_images})\n",
    "\n",
    "print('An exemplary data path with indices of split:')\n",
    "print(*map(lambda x: (x[0]-6, x[1]), enumerate(img_df['path'].iloc[0].split('/'))), sep='\\n', end='\\n\\n')\n",
    "\n",
    "img_id = lambda x: x.split('/')[-3]\n",
    "img_type = lambda in_path: in_path.split('/')[-2]\n",
    "img_group = lambda in_path: in_path.split('/')[-4].split('_')[1]\n",
    "img_stage = lambda in_path: in_path.split('/')[-4].split('_')[0]\n",
    "                           \n",
    "img_df['ImageId'] = img_df['path'].map(img_id)\n",
    "img_df['ImageType'] = img_df['path'].map(img_type)\n",
    "img_df['TrainingSplit'] = img_df['path'].map(img_group)\n",
    "img_df['Stage'] = img_df['path'].map(img_stage)\n",
    "\n",
    "print(img_df.info())\n",
    "img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataframe with training data (image and mask paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "train_df = img_df.query('TrainingSplit==\"train\"')\n",
    "train_rows = []\n",
    "group_cols = ['Stage', 'ImageId']\n",
    "\n",
    "count = 0\n",
    "for group, rows in train_df.groupby(group_cols):\n",
    "    count += 1\n",
    "    if MAX_TRAIN_INSTANCES is not None and count > MAX_TRAIN_INSTANCES:\n",
    "        break\n",
    "    #     print('group', group, 'contains', len(rows), 'rows')\n",
    "    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, group)}\n",
    "    c_row['images'] = rows.query('ImageType == \"images\"')['path'].values.tolist()\n",
    "    c_row['masks'] = rows.query('ImageType == \"masks\"')['path'].values.tolist()\n",
    "    train_rows += [c_row]\n",
    "    \n",
    "train_img_df = pd.DataFrame(train_rows)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "def read(in_img_list):\n",
    "    assert (len(in_img_list) == 1), 'more than one image for this training instance. Shape: ' + str(in_img_list.shape)\n",
    "    return imread(in_img_list[0])\n",
    "\n",
    "IMG_CHANNELS = 3  # restrict pixels to RGB\n",
    "train_img_df['images'] = train_img_df['images'].map(read).map(lambda x: x[:,:,:IMG_CHANNELS])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze intensity distributions\n",
    "\n",
    "The instances form groups and could be handled separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df['Red'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]))\n",
    "train_img_df['Green'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,1]))\n",
    "train_img_df['Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,2]))\n",
    "train_img_df['Gray'] = train_img_df['images'].map(lambda x: np.mean(x))\n",
    "train_img_df['Red-Blue'] = train_img_df['images'].map(lambda x: np.mean(x[:,:,0]-x[:,:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(train_img_df[['Gray', 'Red', 'Green', 'Blue', 'Red-Blue']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df['images'].map(lambda x: x.shape).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis using a single combined mask\n",
    "\n",
    "The masks are simply superimposed for the training and the final individual masks are recovered from extracting connected pixels in the predicted mask. This is expected to come with some inaccuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the masks and save them in dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def read_and_stack(in_img_list):\n",
    "    return np.sum(np.stack([imread(c_img) for c_img in in_img_list], 0), 0) / 255.0\n",
    "\n",
    "train_img_df['masks'] = train_img_df['masks'].map(read_and_stack).map(lambda x: x.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show some of the pictures with their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 6\n",
    "fig, m_axs = plt.subplots(2, n_img, figsize = (12, 4))\n",
    "for (c_row_idx, c_row), (c_im, c_lab) in zip(train_img_df.sample(n_img).iterrows(), \n",
    "                                     m_axs.T):\n",
    "    c_im.imshow(c_row['images'])\n",
    "    c_im.axis('off')\n",
    "    c_im.set_title('Microscope ' + str(c_row_idx))\n",
    "    \n",
    "    c_lab.imshow(c_row['masks'])\n",
    "    c_lab.axis('off')\n",
    "    c_lab.set_title('Labeled ' + str(c_row_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create RLE encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create and test conversion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import label # label regions\n",
    "\n",
    "\n",
    "def rle_encoding(x):\n",
    "    '''\n",
    "    x: numpy array of shape (height, width), 1 - mask, 0 - background\n",
    "    Returns run run length encoding as list\n",
    "    '''\n",
    "    dots = np.where(x.T.flatten()==1)[0] # .T sets order down-then-right\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if (b>prev+1): run_lengths.extend((b+1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def prob_to_rles(x, cut_off = 0.5):\n",
    "    lab_img = label(x>cut_off)\n",
    "    if lab_img.max()<1:\n",
    "        lab_img[0,0] = 1 # ensure at least one prediction per image\n",
    "    for i in range(1, lab_img.max()+1):\n",
    "        yield rle_encoding(lab_img==i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the true mask RLE with the one drawn from the true masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def check_match():\n",
    "    match, mismatch = 0, 0\n",
    "    perfect_masks, imperfect_masks = [], []\n",
    "    count = 0\n",
    "    \n",
    "    for idx, row in tqdm(train_img_df.iterrows()): \n",
    "        isPerfect = True\n",
    "        if idx > 100:\n",
    "            break\n",
    "        count += 1\n",
    "        train_row_rles = list(prob_to_rles(row['masks']))\n",
    "        tl_rles = train_labels.query('ImageId==\"{ImageId}\"'.format(**row))['EncodedPixels']\n",
    "        for img_rle, train_rle in zip(sorted(train_row_rles, key = lambda x: x[0]), \n",
    "                                      sorted(tl_rles, key = lambda x: x[0])):\n",
    "            for i_x, i_y in zip(img_rle, train_rle):\n",
    "                if i_x == i_y:\n",
    "                    match += 1\n",
    "                else:\n",
    "                    mismatch += 1\n",
    "                    isPerfect = False\n",
    "        if isPerfect:\n",
    "            perfect_masks.append((idx, '{ImageId}'.format(**row)))\n",
    "        else:\n",
    "            imperfect_masks.append((idx, '{ImageId}'.format(**row)))\n",
    "\n",
    "    print('Matches: %d, Mismatches: %d, Accuracy: %2.1f%%' % (match, mismatch, 100*match/(match+mismatch)))\n",
    "    print('Fully correct masks: {} / {} = {:.1f}%'.format(len(perfect_masks), count, \n",
    "                                                       100*len(perfect_masks)/count))\n",
    "\n",
    "    n_img_max = 5\n",
    "    \n",
    "    n_img = min(n_img_max, len(imperfect_masks))\n",
    "    idxList = [i[0] for i in imperfect_masks][-n_img:]\n",
    "    \n",
    "    fig, m_axs = plt.subplots(2, n_img, figsize = (12, 6))\n",
    "    print('Some failing and some successfull mask encodings:')\n",
    "    for (_, d_row), (c_im, c_lab) in zip(train_img_df.iloc[idxList].iterrows(), m_axs.T):\n",
    "        \n",
    "        c_im.imshow(d_row['images'])\n",
    "        c_im.axis('off')\n",
    "        c_im.set_title('Img ' + d_row['ImageId'][:8])\n",
    "\n",
    "        c_lab.imshow(d_row['masks'])\n",
    "        c_lab.axis('off')\n",
    "        c_lab.set_title('Bad ' + d_row['ImageId'][:8])\n",
    "    \n",
    "    n_img = min(n_img_max, len(perfect_masks))\n",
    "    idxList = [i[0] for i in perfect_masks][-n_img:]\n",
    "    \n",
    "    fig, m_axs = plt.subplots(2, n_img, figsize = (12, 6))\n",
    "    for (_, d_row), (c_im, c_lab) in zip(train_img_df.iloc[idxList].iterrows(), m_axs.T):\n",
    "        \n",
    "        c_im.imshow(d_row['images'])\n",
    "        c_im.axis('off')\n",
    "        c_im.set_title('Img ' + d_row['ImageId'][:8])\n",
    "\n",
    "        c_lab.imshow(d_row['masks'])\n",
    "        c_lab.axis('off')\n",
    "        c_lab.set_title('Good ' + d_row['ImageId'][:8])\n",
    "    \n",
    "check_match()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build simple CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, UpSampling2D, Lambda\n",
    "simple_cnn = Sequential()\n",
    "simple_cnn.add(BatchNormalization(input_shape = (None, None, IMG_CHANNELS), \n",
    "                                  name = 'NormalizeInput'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n",
    "simple_cnn.add(Conv2D(8, kernel_size = (3,3), padding = 'same'))\n",
    "# use dilations to get a slightly larger field of view\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (3,3), dilation_rate = 2, padding = 'same'))\n",
    "simple_cnn.add(Conv2D(32, kernel_size = (3,3), dilation_rate = 3, padding = 'same'))\n",
    "\n",
    "# the final processing\n",
    "simple_cnn.add(Conv2D(16, kernel_size = (1,1), padding = 'same'))\n",
    "simple_cnn.add(Conv2D(1, kernel_size = (1,1), padding = 'same', activation = 'sigmoid'))\n",
    "simple_cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom loss to match competition objective\n",
    "\n",
    "Use Dice score, see [here](https://arxiv.org/pdf/1707.00478.pdf). Omit the factor 2 from the paper to have a IoU (Intersection over Unit) interpretation of the value. This formulation deviates from the one in the [kaggle evaluation description](https://www.kaggle.com/c/data-science-bowl-2018#evaluation) due to the fact that here, all masks are merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "smooth = 0.01\n",
    "\n",
    "\n",
    "def dice(y_true, y_pred):\n",
    "    y_true_f = y_true.flatten()\n",
    "    y_pred_f = y_pred.flatten()\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return (intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "simple_cnn.compile(optimizer = 'adam', loss = dice_coef_loss, metrics = [dice_coef, 'acc', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use one image at a time for training (training step = one image, one epoch finished when all images processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_gen():\n",
    "    while True:\n",
    "        for _, c_row in train_img_df.iterrows():\n",
    "            yield np.expand_dims(c_row['images'],0), np.expand_dims(np.expand_dims(c_row['masks'],-1),0)\n",
    "\n",
    "nxt = next(simple_gen())\n",
    "print('Elements in each generated object:', len(nxt))\n",
    "print('Shape of instance data: ', nxt[0].shape)\n",
    "print('Shape of instance label:', nxt[1].shape)\n",
    "# print(nxt[1][0][255][255][0])\n",
    "# print(nxt[0][0][255][255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import datetime\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "from keras.models import load_model\n",
    "import h5py\n",
    "\n",
    "if REDO_TRAINING:\n",
    "    simple_cnn.fit_generator(simple_gen(), min(STEPS_PER_EPOCH, train_img_df.shape[0]), epochs = N_EPOCHS)\n",
    "    timeStamp = time.time()\n",
    "    timeStamp = datetime.datetime.fromtimestamp(timeStamp).strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    saveName = 'simple_gen_' + timeStamp + '.h5'\n",
    "    simple_cnn.save(saveName)\n",
    "    subprocess.call(['cp', saveName, 'simple_gen.h5'])\n",
    "    \n",
    "else:\n",
    "    simple_cnn = load_model('simple_gen.h5', custom_objects={'dice_coef_loss': dice_coef_loss, 'dice_coef': dice_coef})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show predictions vs labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 3\n",
    "\n",
    "display_training_img_df = train_img_df.sample(n_img)\n",
    "\n",
    "display_training_img_df['predictions'] = display_training_img_df['images'].map(lambda x: simple_cnn.predict(np.expand_dims(x, 0))[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import closing, opening, disk\n",
    "\n",
    "\n",
    "def clean_img(x):\n",
    "    # remove cracks and small dots\n",
    "    return opening(closing(x, disk(1)), disk(3))\n",
    "\n",
    "\n",
    "fig, m_axs = plt.subplots(4, n_img, figsize = (12, 16))\n",
    "for (_, d_row), (c_im, c_lab, c_dirty, c_clean) in zip(display_training_img_df.iterrows(), m_axs.T):\n",
    "    c_im.imshow(d_row['images'])\n",
    "    c_im.axis('off')\n",
    "    c_im.set_title('Microscope')\n",
    "    \n",
    "    c_lab.imshow(d_row['masks'])\n",
    "    c_lab.axis('off')\n",
    "    c_lab.set_title('Label')\n",
    "    \n",
    "    dirty_im = d_row['predictions']\n",
    "    dice_coeff = dice(d_row['masks'], dirty_im)\n",
    "    \n",
    "    c_dirty.imshow(dirty_im)\n",
    "    c_dirty.axis('off')\n",
    "    c_dirty.set_title('Prediction\\n Dice {:.2f}'.format(dice_coeff))\n",
    "    \n",
    "    clean_im = clean_img(d_row['predictions'])\n",
    "    dice_coeff = dice(d_row['masks'], clean_im)\n",
    "    \n",
    "    c_clean.imshow(clean_im)\n",
    "    c_clean.axis('off')\n",
    "    c_clean.set_title('Clean prediction\\n Dice {:.2f}'.format(dice_coeff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "test_df = img_df.query('TrainingSplit==\"test\"')\n",
    "test_rows = []\n",
    "group_cols = ['Stage', 'ImageId']\n",
    "for group, rows in test_df.groupby(group_cols):\n",
    "    c_row = {col_name: col_value for col_name, col_value in zip(group_cols, group)}\n",
    "    c_row['images'] = rows.query('ImageType == \"images\"')['path'].values.tolist()\n",
    "    test_rows += [c_row]\n",
    "test_img_df = pd.DataFrame(test_rows)   \n",
    "\n",
    "test_img_df['images'] = test_img_df['images'].map(read).map(lambda x: x[:,:,:IMG_CHANNELS])\n",
    "print(test_img_df.shape[0], 'images to process')\n",
    "print(test_img_df.sample(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check test image dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_df['images'].map(lambda x: x.shape).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "test_img_df['masks'] = test_img_df['images'].map(lambda x: simple_cnn.predict(np.expand_dims(x, 0))[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show some predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_img = 3\n",
    "\n",
    "fig, m_axs = plt.subplots(3, n_img, figsize = (12, 10))\n",
    "for (_, d_row), (c_im, c_lab, c_clean) in zip(test_img_df.sample(n_img).iterrows(), \n",
    "                                     m_axs.T):\n",
    "    c_im.imshow(d_row['images'])\n",
    "    c_im.axis('off')\n",
    "    c_im.set_title('Microscope')\n",
    "    \n",
    "    c_lab.imshow(d_row['masks'])\n",
    "    c_lab.axis('off')\n",
    "    c_lab.set_title('Predicted')\n",
    "    \n",
    "    c_clean.imshow(clean_img(d_row['masks']))\n",
    "    c_clean.axis('off')\n",
    "    c_clean.set_title('Clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert predictions to RLEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_df['rles'] = test_img_df['masks'].map(clean_img).map(lambda x: list(prob_to_rles(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred_list = []\n",
    "\n",
    "for _, c_row in test_img_df.iterrows():\n",
    "    for c_rle in c_row['rles']:\n",
    "        out_pred_list+=[dict(ImageId=c_row['ImageId'], EncodedPixels = ' '.join(np.array(c_rle).astype(str)))]\n",
    "\n",
    "out_pred_df = pd.DataFrame(out_pred_list)\n",
    "print(out_pred_df.shape[0], 'regions found for', test_img_df.shape[0], 'images')\n",
    "out_pred_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred_df[['ImageId', 'EncodedPixels']].to_csv('results/result_cnn_single_mask.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
