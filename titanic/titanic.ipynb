{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic data challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "showPlots = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "apply_df = pd.read_csv('data/test.csv')\n",
    "print(train_df[:3], '\\n')\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test submissions\n",
    "Test files:\n",
    "* random prediction\n",
    "* survival for women and children only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createRandom, createWomenChildren = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createRandom:\n",
    "    # Create dummy random output for first submission\n",
    "    id_df = apply_df['PassengerId']\n",
    "    random_df = pd.DataFrame(np.random.randint(low=0, high=2, size=(id_df.shape[0], 1)), columns=['Survived'])\n",
    "    result_df = pd.concat([id_df, random_df], axis=1)\n",
    "\n",
    "    # Save output to file\n",
    "    result_df.to_csv(\"results/result_random.csv\", index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createWomenChildren:\n",
    "    # Create dummy output with survival for women and children only\n",
    "    result_df = apply_df\n",
    "    result_df['Survived'] = ((result_df['Sex'] == 'female') | (result_df['Age'] < 16)).astype(int)\n",
    "\n",
    "    # Save output to file\n",
    "    result_df.to_csv(\"results/result_children_women.csv\", columns=['PassengerId', 'Survived'], index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a general look\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique entries\n",
    "train_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many men\n",
    "train_df.loc[train_df['Sex'] == 'male'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "### Remove unusable data\n",
    "* drop PassengerId, Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_full = train_df.drop([\"Survived\", \"PassengerId\", \"Ticket\"], axis=1)\n",
    "y_full = train_df[\"Survived\"]\n",
    "X_apply = apply_df.drop([\"PassengerId\", \"Ticket\"], axis=1)\n",
    "X_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform non-numeric labels\n",
    "* fill NaN values with sensible defaults\n",
    "* fill missing values with medians\n",
    "* integer labels for 'Sex', 'Embarked' and 'Cabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class MyNumericizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_cabin_info=True):\n",
    "        # no *args, **kargs to make use of BaseEstimator class\n",
    "        # other args can be steered later as hyperparameters\n",
    "        self.add_cabin_info = add_cabin_info\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Sex\n",
    "        binarizer = LabelBinarizer(sparse_output=False)\n",
    "        col = X['Sex']\n",
    "        col = pd.DataFrame(binarizer.fit_transform(col), columns=['Sex'])\n",
    "        X = X.drop('Sex', axis=1)\n",
    "        X = pd.concat([X, col], axis=1)\n",
    "        # Embarked\n",
    "        encoder = LabelEncoder()\n",
    "        X['Embarked'].fillna('unknown', inplace=True)\n",
    "        col = encoder.fit_transform(X['Embarked'])\n",
    "        col = pd.DataFrame(col, columns=['Embarked'])\n",
    "        X = X.drop('Embarked', axis=1)\n",
    "        X = pd.concat([X, col], axis=1)\n",
    "        #cabin\n",
    "        if self.add_cabin_info:\n",
    "            encoder = LabelEncoder()\n",
    "            X['Cabin'].fillna('unknown', inplace=True)\n",
    "            col = encoder.fit_transform(X['Cabin'])\n",
    "            col = pd.DataFrame(col, columns=['Cabin'])\n",
    "            X = X.drop('Cabin', axis=1)\n",
    "            X = pd.concat([X, col], axis=1)\n",
    "        else:\n",
    "            X = X.drop(['Cabin'], axis=1)\n",
    "        #Age\n",
    "        median = X['Age'].median()\n",
    "        X['Age'].fillna(median, inplace=True)\n",
    "        #Fare\n",
    "        median = X['Fare'].median()\n",
    "        X['Fare'].fillna(median, inplace=True)\n",
    "        \n",
    "        if X.isnull().any().any():\n",
    "            print('Warning: null value detected:')\n",
    "            print(X.isnull().any())\n",
    "            \n",
    "        return X\n",
    "\n",
    "# print(X_new.head())\n",
    "# scaler = StandardScaler()\n",
    "# X_new = scaler.fit_transform(X_new)\n",
    "# print(pd.DataFrame(X_new, columns = X_full.columns).head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "#### Before transformation to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "if showPlots:\n",
    "    plt.figure()\n",
    "    X_full.hist(bins=50, figsize=(20, 15))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After transformation to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_num = MyNumericizer()\n",
    "X_plot = my_num.fit_transform(X_full)\n",
    "\n",
    "if showPlots:\n",
    "    plt.figure()\n",
    "    X_plot.hist(bins=50, figsize=(20, 15))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showPlots:\n",
    "    plt.figure()\n",
    "    scatter_matrix(pd.concat([X_plot, y_full], axis=1), figsize=(12, 8))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a closer look at single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "\n",
    "# if showPlots:\n",
    "#     g = sns.FacetGrid(train_df, col='Survived')\n",
    "#     g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if showPlots:\n",
    "#     # grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "#     grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "#     grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "#     grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if showPlots:\n",
    "#     # grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "#     grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\n",
    "#     grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "#     grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if showPlots:\n",
    "#     # grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "#     grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "#     grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "#     grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "* number of family members\n",
    "* coarser binning for age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_relatives=True, add_nobility=False):\n",
    "        self.add_nobility = add_nobility\n",
    "        self.add_relatives = add_relatives\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.add_nobility:\n",
    "            def extract_nobility(row):\n",
    "                name = row['Name']\n",
    "                if 'Lady' in name:\n",
    "                    return 1\n",
    "                if 'Sir' in name:\n",
    "                    return 1\n",
    "                return 0\n",
    "            \n",
    "            X['Nobility'] = X.apply(lambda row: extract_nobility(row), axis=1)\n",
    "        if self.add_relatives:\n",
    "            X['Family'] = X['SibSp'] + X['Parch']\n",
    "        X = X.drop('Name', axis=1)\n",
    "        return X\n",
    "\n",
    "feat_adder = MyFeatureAdder()\n",
    "X_new = feat_adder.fit_transform(X_full)\n",
    "print(X_new.head())\n",
    "# X_new.loc[X_new['Nobility'] == 1].count()\n",
    "# print(X_new['Name'].where(X_new['Pclass'] == 1).dropna())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "add_cabin_info = False  # adding this reduces accuracy\n",
    "add_relatives = True  # adding this increases accuracy\n",
    "add_nobility = False  # in current implementation reduces accuracy\n",
    "\n",
    "clfs = {}\n",
    "\n",
    "clfs['linear_svc'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_svc', LinearSVC(C=1, loss='hinge')),\n",
    "        ))\n",
    "\n",
    "clfs['rbf_svc'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rbf_svc', SVC(kernel='rbf', C=1)),\n",
    "        ))\n",
    "\n",
    "clfs['poly_svc'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly_svc', SVC(kernel='poly', C=1)),\n",
    "        ))\n",
    "\n",
    "clfs['tree'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('tree', DecisionTreeClassifier()),\n",
    "        ))\n",
    "\n",
    "clfs['kNN'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kNN', KNeighborsClassifier()),\n",
    "        ))\n",
    "\n",
    "clfs['gradBoost'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('gradBoost', GradientBoostingClassifier(learning_rate=1.0, n_estimators=3, max_depth=2)),\n",
    "        ))\n",
    "\n",
    "clfs['randomForest'] = Pipeline((\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_nobility=add_nobility)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('randomForest', RandomForestClassifier()),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Split training sample into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.25, random_state=1337)\n",
    "# Reset the index to reach from 0 to n-1 to avoid NaN rows\n",
    "for x in [X_train, X_test, y_train, y_test]:\n",
    "    x.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in clfs.items():\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "for name, clf in clfs.items():\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    accuracies.append((name, accuracy))\n",
    "    \n",
    "accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "for acc in accuracies:\n",
    "    print(acc[0], ':', *acc[1:])\n",
    "\n",
    "top = accuracies[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfs[top].predict(X_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pred = pd.DataFrame(apply_df['PassengerId'])\n",
    "y_pred = pd.DataFrame(y_pred, columns=['Survived'])\n",
    "result_df = pd.concat([id_pred, y_pred], axis=1)\n",
    "print(result_df.head())\n",
    "\n",
    "# Save output to file\n",
    "result_df.to_csv(\"results/result.csv\", index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
