{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Titanic data challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings\n",
    "showPlots = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "apply_df = pd.read_csv('data/test.csv')\n",
    "print(train_df[:3], '\\n')\n",
    "print(train_df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test submissions\n",
    "Test files:\n",
    "* random prediction\n",
    "* survival for women and children only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "createRandom, createWomenChildren = False, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createRandom:\n",
    "    # Create dummy random output for first submission\n",
    "    id_df = apply_df['PassengerId']\n",
    "    random_df = pd.DataFrame(np.random.randint(low=0, high=2, size=(id_df.shape[0], 1)), columns=['Survived'])\n",
    "    result_df = pd.concat([id_df, random_df], axis=1)\n",
    "\n",
    "    # Save output to file\n",
    "    result_df.to_csv(\"results/result_random.csv\", index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if createWomenChildren:\n",
    "    # Create dummy output with survival for women and children only\n",
    "    result_df = apply_df\n",
    "    result_df['Survived'] = ((result_df['Sex'] == 'female') | (result_df['Age'] < 16)).astype(int)\n",
    "\n",
    "    # Save output to file\n",
    "    result_df.to_csv(\"results/result_children_women.csv\", columns=['PassengerId', 'Survived'], index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a general look\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find how many unique entries\n",
    "train_df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many men\n",
    "train_df.loc[train_df['Sex'] == 'male'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take a closer look at single features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "if showPlots:\n",
    "    g = sns.FacetGrid(train_df, col='Survived')\n",
    "    g.map(plt.hist, 'Age', bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showPlots:\n",
    "    # grid = sns.FacetGrid(train_df, col='Pclass', hue='Survived')\n",
    "    grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "    grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "    grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showPlots:\n",
    "    grid = sns.FacetGrid(train_df, col='Embarked')\n",
    "#     grid = sns.FacetGrid(train_df, row='Embarked', size=2.2, aspect=1.6)\n",
    "    grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep', \n",
    "             hue_order=['female', 'male'], order=[1,2,3])\n",
    "    grid.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showPlots:\n",
    "#     grid = sns.FacetGrid(train_df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "    grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "    grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None, order=['female', 'male'])\n",
    "    grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unusable data\n",
    "* drop PassengerId, Ticket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_full = train_df.drop([\"Survived\", \"PassengerId\", \"Ticket\"], axis=1)\n",
    "y_full = train_df[\"Survived\"]\n",
    "X_apply = apply_df.drop([\"PassengerId\", \"Ticket\"], axis=1)\n",
    "X_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "* number of family members\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "* coarser binning for age?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class MyFeatureAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_relatives=True, add_title=True):\n",
    "        self.add_title = add_title\n",
    "        self.add_relatives = add_relatives\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if self.add_title:\n",
    "            pd.options.mode.chained_assignment = None  # creates slice-copy assignment warning\n",
    "            X['Title'] = X.Name.str.extract(r' ([A-Za-z]+)\\.', expand=False)\n",
    "            X['Title'].replace(['Lady', 'Countess', 'Capt', 'Col',\n",
    "                                'Don', 'Dr', 'Major', 'Rev', 'Sir',\n",
    "                                'Jonkheer', 'Dona'],\n",
    "                                'Rare', inplace=True)\n",
    "            X['Title'].replace('Mlle', 'Miss', inplace=True)\n",
    "            X['Title'].replace('Ms', 'Miss', inplace=True)\n",
    "            X['Title'].replace('Mme', 'Mrs', inplace=True)\n",
    "            pd.options.mode.chained_assignment = 'warn'\n",
    "\n",
    "        if self.add_relatives:\n",
    "#             X.loc[:, 'Family'] = X['SibSp'] + X['Parch']  # creates slice-copy assignment warning\n",
    "            Xtmp = pd.DataFrame(X['SibSp'] + X['Parch'], columns=['Family'])\n",
    "            X = pd.concat([X, Xtmp], axis=1)\n",
    "        X = X.drop('Name', axis=1)\n",
    "        return X\n",
    "\n",
    "# feat_adder = MyFeatureAdder()\n",
    "# X_new = feat_adder.fit_transform(X_full)\n",
    "# print(X_new.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform non-numeric labels to numeric ones\n",
    "* fill NaN values with sensible defaults\n",
    "* fill missing values with medians\n",
    "* integer labels for 'Sex', 'Embarked' and 'Cabin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class MyNumericizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_cabin_info=True):\n",
    "        # no *args, **kargs to make use of BaseEstimator class\n",
    "        # other args can be steered later as hyperparameters\n",
    "        self.add_cabin_info = add_cabin_info\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing to do\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        # Sex\n",
    "        binarizer = LabelBinarizer(sparse_output=False)\n",
    "        X['Sex'] = binarizer.fit_transform(X['Sex'])\n",
    "        # Embarked\n",
    "        encoder = LabelEncoder()\n",
    "        X['Embarked'].fillna('unknown', inplace=True)\n",
    "        X['Embarked'] = encoder.fit_transform(X['Embarked'])\n",
    "        #cabin\n",
    "        encoder = LabelEncoder()\n",
    "        if self.add_cabin_info:\n",
    "            X['Cabin'].fillna('unknown', inplace=True)\n",
    "            X['Cabin'] = encoder.fit_transform(X['Cabin'])\n",
    "        else:\n",
    "            X = X.drop(['Cabin'], axis=1)\n",
    "        # Age\n",
    "        median = X['Age'].median()\n",
    "        X['Age'].fillna(median, inplace=True)\n",
    "        # Fare\n",
    "        median = X['Fare'].median()\n",
    "        X['Fare'].fillna(median, inplace=True)\n",
    "        # Title\n",
    "        X['Title'].fillna('unknown', inplace=True)\n",
    "        X['Title'] = encoder.fit_transform(X['Title'])\n",
    "        \n",
    "        if X.isnull().any().any():\n",
    "            print('Warning: null value detected:')\n",
    "            print(X.isnull().any())\n",
    "            \n",
    "        return X\n",
    "\n",
    "\n",
    "# print(X_full.head())\n",
    "# feat_adder = MyFeatureAdder()\n",
    "# X_new = feat_adder.fit_transform(X_full)\n",
    "# print(X_new.head())\n",
    "# numericizer = MyNumericizer()\n",
    "# X_new = numericizer.fit_transform(X_new)\n",
    "# print(X_new.head())\n",
    "# scaler = StandardScaler()\n",
    "# colNames = X_new.columns\n",
    "# X_new = scaler.fit_transform(X_new)\n",
    "# print(pd.DataFrame(X_new, columns=colNames).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "#### Before transformation to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "if showPlots:\n",
    "    plt.figure()\n",
    "    X_full.hist(bins=50, figsize=(20, 15))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After transformation to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_adder = MyFeatureAdder()\n",
    "my_num = MyNumericizer()\n",
    "X_plot = my_num.fit_transform(feat_adder.fit_transform(X_full))\n",
    "\n",
    "if showPlots:\n",
    "    plt.figure()\n",
    "    X_plot.hist(bins=50, figsize=(20, 15))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if showPlots:\n",
    "    plt.figure()\n",
    "    scatter_matrix(pd.concat([X_plot, y_full], axis=1), figsize=(12, 8))\n",
    "    1  # prevent matlpotlib printout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "add_cabin_info = False  # adding this worsens accuracy\n",
    "add_relatives = True  # adding this improves accuracy\n",
    "add_title = True  # in current implementation worsens accuracy\n",
    "\n",
    "clfs = {}\n",
    "\n",
    "clfs['linear_svc'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('linear_svc', LinearSVC(C=1, loss='hinge')),\n",
    "        ))\n",
    "\n",
    "clfs['rbf_svc'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('rbf_svc', SVC(kernel='rbf', C=1)),\n",
    "        ))\n",
    "\n",
    "clfs['poly_svc'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('poly_svc', SVC(kernel='poly', C=1)),\n",
    "        ))\n",
    "\n",
    "clfs['tree'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('tree', DecisionTreeClassifier()),\n",
    "        ))\n",
    "\n",
    "clfs['kNN'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('kNN', KNeighborsClassifier()),\n",
    "        ))\n",
    "\n",
    "clfs['gradBoost'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('gradBoost', GradientBoostingClassifier(learning_rate=1.0, n_estimators=3, max_depth=2)),\n",
    "        ))\n",
    "\n",
    "clfs['randomForest'] = Pipeline((\n",
    "        ('MyFeatureAdder', MyFeatureAdder(add_relatives=add_relatives, add_title=add_title)),\n",
    "        ('MyNumericizer', MyNumericizer(add_cabin_info=add_cabin_info)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('randomForest', RandomForestClassifier()),\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "### Split training sample into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_full, y_full, test_size=0.25, random_state=1337)\n",
    "# Reset the index to reach from 0 to n-1 to avoid NaN rows\n",
    "for x in [X_train, X_test, y_train, y_test]:\n",
    "    x.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, clf in clfs.items():\n",
    "    clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracies = []\n",
    "for name, clf in clfs.items():\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
    "    accuracies.append((name, accuracy))\n",
    "    \n",
    "accuracies.sort(key=lambda x: x[1], reverse=True)\n",
    "for acc in accuracies:\n",
    "    print(acc[0], ':', *acc[1:])\n",
    "\n",
    "top = accuracies[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clfs[top].predict(X_apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_pred = pd.DataFrame(apply_df['PassengerId'])\n",
    "y_pred = pd.DataFrame(y_pred, columns=['Survived'])\n",
    "result_df = pd.concat([id_pred, y_pred], axis=1)\n",
    "print(result_df.head())\n",
    "\n",
    "# Save output to file\n",
    "result_df.to_csv(\"results/result.csv\", index=False, float_format='%.0f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
